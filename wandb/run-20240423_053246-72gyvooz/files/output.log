  0%|                                                                                          | 0/5010 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
/home/s/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/s/anaconda3/envs/luongtk/lib/python3.8/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")








































































































  7%|█████▎                                                                          | 334/5010 [03:30<48:49,  1.60it/s]
  warnings.warn(
/home/s/anaconda3/envs/luongtk/lib/python3.8/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
{'eval_loss': 0.38865676522254944, 'eval_accuracy': 0.8703148425787106, 'eval_precision': 0.8379200988724853, 'eval_recall': 0.7638073895285331, 'eval_f1': 0.7918437034487281, 'eval_runtime': 2.4992, 'eval_samples_per_second': 533.775, 'eval_steps_per_second': 2.401, 'epoch': 1.0}



















































 10%|███████▉                                                                        | 500/5010 [05:18<46:56,  1.60it/s]




















































 13%|██████████▋                                                                     | 668/5010 [07:02<44:53,  1.61it/s]
  warnings.warn(
/home/s/anaconda3/envs/luongtk/lib/python3.8/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
{'eval_loss': 0.3263281583786011, 'eval_accuracy': 0.8710644677661169, 'eval_precision': 0.8057376854893833, 'eval_recall': 0.8240389557868013, 'eval_f1': 0.8135335401616847, 'eval_runtime': 2.44, 'eval_samples_per_second': 546.723, 'eval_steps_per_second': 2.459, 'epoch': 2.0}























































































 20%|███████████████▉                                                                | 999/5010 [10:02<42:07,  1.59it/s]
 20%|███████████████▊                                                               | 1002/5010 [10:04<41:25,  1.61it/s]

  0%|                                                                                             | 0/6 [00:00<?, ?it/s]
 20%|███████████████▊                                                               | 1002/5010 [10:06<41:25,  1.61it/s]/home/s/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/s/anaconda3/envs/luongtk/lib/python3.8/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")







































































































 27%|█████████████████████                                                          | 1336/5010 [13:35<38:00,  1.61it/s]
  warnings.warn(
/home/s/anaconda3/envs/luongtk/lib/python3.8/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
{'eval_loss': 0.2819787561893463, 'eval_accuracy': 0.896551724137931, 'eval_precision': 0.8610241714130131, 'eval_recall': 0.8304123512620967, 'eval_f1': 0.8445110183617837, 'eval_runtime': 2.4552, 'eval_samples_per_second': 543.342, 'eval_steps_per_second': 2.444, 'epoch': 4.0}


















































 30%|███████████████████████▋                                                       | 1501/5010 [15:21<35:56,  1.63it/s]




































 33%|██████████████████████████▎                                                    | 1669/5010 [16:34<11:42,  4.76it/s]
  warnings.warn(
/home/s/anaconda3/envs/luongtk/lib/python3.8/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
 33%|██████████████████████████▍                                                    | 1675/5010 [16:37<16:49,  3.31it/s]




























































































 40%|███████████████████████████████▌                                               | 2000/5010 [19:41<30:56,  1.62it/s]

 40%|███████████████████████████████▌                                               | 2004/5010 [19:43<30:51,  1.62it/s]
  warnings.warn(
/home/s/anaconda3/envs/luongtk/lib/python3.8/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
 40%|██████████████████████████████▊                                              | 2005/5010 [19:47<1:16:59,  1.54s/it]







































































































 47%|████████████████████████████████████▊                                          | 2338/5010 [23:15<27:41,  1.61it/s]

  0%|                                                                                             | 0/6 [00:00<?, ?it/s]
 47%|████████████████████████████████████▊                                          | 2338/5010 [23:17<27:41,  1.61it/s]/home/s/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/s/anaconda3/envs/luongtk/lib/python3.8/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")


















































 50%|███████████████████████████████████████▍                                       | 2500/5010 [24:59<26:22,  1.59it/s]


















































 53%|██████████████████████████████████████████▏                                    | 2672/5010 [26:40<23:57,  1.63it/s]
  warnings.warn(
/home/s/anaconda3/envs/luongtk/lib/python3.8/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
{'eval_loss': 0.2675277590751648, 'eval_accuracy': 0.9010494752623688, 'eval_precision': 0.8557853803625266, 'eval_recall': 0.852223014560177, 'eval_f1': 0.8539681386255734, 'eval_runtime': 2.4201, 'eval_samples_per_second': 551.219, 'eval_steps_per_second': 2.479, 'epoch': 8.0}






































































































 60%|███████████████████████████████████████████████▎                               | 3002/5010 [30:10<21:11,  1.58it/s]

 60%|███████████████████████████████████████████████▍                               | 3006/5010 [30:13<21:04,  1.58it/s]
  warnings.warn(
/home/s/anaconda3/envs/luongtk/lib/python3.8/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
{'eval_loss': 0.26323145627975464, 'eval_accuracy': 0.9085457271364318, 'eval_precision': 0.8622121879826767, 'eval_recall': 0.8670595704442872, 'eval_f1': 0.864561695913239, 'eval_runtime': 2.4305, 'eval_samples_per_second': 548.869, 'eval_steps_per_second': 2.469, 'epoch': 9.0}







































































































 67%|████████████████████████████████████████████████████▋                          | 3340/5010 [33:44<17:11,  1.62it/s]
  warnings.warn(
/home/s/anaconda3/envs/luongtk/lib/python3.8/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
 67%|████████████████████████████████████████████████████▋                          | 3341/5010 [33:48<42:47,  1.54s/it]














































 70%|███████████████████████████████████████████████████████▏                       | 3501/5010 [35:20<15:46,  1.59it/s]






















































 73%|█████████████████████████████████████████████████████████▉                     | 3674/5010 [37:08<13:44,  1.62it/s]
 83%|██████████████████████████████████████████████████████████████████████▊              | 5/6 [00:01<00:00,  2.67it/s]
  warnings.warn(
/home/s/anaconda3/envs/luongtk/lib/python3.8/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")






































































































 80%|███████████████████████████████████████████████████████████████                | 4002/5010 [40:36<10:26,  1.61it/s]

 80%|███████████████████████████████████████████████████████████████▏               | 4008/5010 [40:40<10:15,  1.63it/s]

  0%|                                                                                             | 0/6 [00:00<?, ?it/s]
 80%|███████████████████████████████████████████████████████████████▏               | 4008/5010 [40:42<10:15,  1.63it/s]/home/s/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/s/anaconda3/envs/luongtk/lib/python3.8/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")























































































 87%|████████████████████████████████████████████████████████████████████▍          | 4342/5010 [43:38<03:14,  3.44it/s]
 87%|████████████████████████████████████████████████████████████████████▍          | 4342/5010 [43:38<03:14,  3.44it/s]/home/s/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/s/anaconda3/envs/luongtk/lib/python3.8/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")



















































 90%|██████████████████████████████████████████████████████████████████████▉        | 4501/5010 [45:23<05:19,  1.59it/s]






















































 93%|█████████████████████████████████████████████████████████████████████████▋     | 4676/5010 [47:12<03:27,  1.61it/s]
  warnings.warn(
/home/s/anaconda3/envs/luongtk/lib/python3.8/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
{'eval_loss': 0.26341116428375244, 'eval_accuracy': 0.9100449775112444, 'eval_precision': 0.8647004628143897, 'eval_recall': 0.8691458431784, 'eval_f1': 0.8666972812401508, 'eval_runtime': 2.4887, 'eval_samples_per_second': 536.018, 'eval_steps_per_second': 2.411, 'epoch': 14.0}





































































































100%|██████████████████████████████████████████████████████████████████████████████▊| 5002/5010 [50:39<00:05,  1.59it/s]


100%|███████████████████████████████████████████████████████████████████████████████| 5010/5010 [50:44<00:00,  1.63it/s]

 50%|██████████████████████████████████████████▌                                          | 3/6 [00:00<00:00,  3.15it/s]
{'eval_loss': 0.2629338502883911, 'eval_accuracy': 0.9100449775112444, 'eval_precision': 0.8663504656248464, 'eval_recall': 0.8680999516523674, 'eval_f1': 0.8668832653856767, 'eval_runtime': 2.4907, 'eval_samples_per_second': 535.587, 'eval_steps_per_second': 2.409, 'epoch': 15.0}
{'train_runtime': 3051.9626, 'train_samples_per_second': 52.447, 'train_steps_per_second': 1.642, 'train_loss': 0.2919742632054997, 'epoch': 15.0}